\documentclass[11pt]{article}

% Change "review" to "final" to generate the final (sometimes called camera-ready) version.
% Change to "preprint" to generate a non-anonymous version with page numbers.
\usepackage[]{acl}
\usepackage{times}
\usepackage{latexsym}

% For proper rendering and hyphenation of words containing Latin characters (including in bib files)
\usepackage[T1]{fontenc}
% For Vietnamese characters
% \usepackage[T5]{fontenc}
% See https://www.latex-project.org/help/documentation/encguide.pdf for other character sets

% This assumes your files are encoded as UTF8
\usepackage[utf8]{inputenc}
\usepackage{microtype}
\usepackage{inconsolata}
\usepackage{graphicx}

\usepackage{url}
\usepackage{hyperref}

% If the title and author information does not fit in the area allocated, uncomment the following
%
%\setlength\titlebox{<dim>}
%
% and set <dim> to something 5cm or larger.

\title{Group 147 Progress Report:\\No More Parties In LA}

\author{Arjun Karthik, Alina Zeng, Stanley Chen \\
  \texttt{\{kartha4,zenga12,chens313\}@mcmaster.ca} }

%\author{
%  \textbf{First Author\textsuperscript{1}},
%  \textbf{Second Author\textsuperscript{1,2}},
%  \textbf{Third T. Author\textsuperscript{1}},
%  \textbf{Fourth Author\textsuperscript{1}},
%\\
%  \textbf{Fifth Author\textsuperscript{1,2}},
%  \textbf{Sixth Author\textsuperscript{1}},
%  \textbf{Seventh Author\textsuperscript{1}},
%  \textbf{Eighth Author \textsuperscript{1,2,3,4}},
%\\
%  \textbf{Ninth Author\textsuperscript{1}},
%  \textbf{Tenth Author\textsuperscript{1}},
%  \textbf{Eleventh E. Author\textsuperscript{1,2,3,4,5}},
%  \textbf{Twelfth Author\textsuperscript{1}},
%\\
%  \textbf{Thirteenth Author\textsuperscript{3}},
%  \textbf{Fourteenth F. Author\textsuperscript{2,4}},
%  \textbf{Fifteenth Author\textsuperscript{1}},
%  \textbf{Sixteenth Author\textsuperscript{1}},
%\\
%  \textbf{Seventeenth S. Author\textsuperscript{4,5}},
%  \textbf{Eighteenth Author\textsuperscript{3,4}},
%  \textbf{Nineteenth N. Author\textsuperscript{2,5}},
%  \textbf{Twentieth Author\textsuperscript{1}}
%\\
%\\
%  \textsuperscript{1}Affiliation 1,
%  \textsuperscript{2}Affiliation 2,
%  \textsuperscript{3}Affiliation 3,
%  \textsuperscript{4}Affiliation 4,
%  \textsuperscript{5}Affiliation 5
%\\
%  \small{
%    \textbf{Correspondence:} \href{mailto:email@domain}{email@domain}
%  }
%}

\begin{document}
\maketitle
% \begin{abstract}
% \end{abstract}

\section{Introduction}

This project aims to predict the weekly occurrence of major crime types across Los Angeles using publicly available data from the Los Angeles Police Department. Predicting crime patterns is a valuable tool for law enforcement and city planners, as it supports proactive decision-making, effective resource allocation, and early detection of emerging hot spots. The model developed in this work predicts whether a given crime type will occur in a particular region of the city during a specific week.

Our approach frames the problem as a multi-label binary classification task, where each label represents a different crime type. By incorporating short-term historical data through rolling temporal features, we enable the model to capture recent trends in crime dynamics. The focus is on establishing a clear and explainable baseline model that accurately captures temporal dependencies while serving as a foundation for more advanced methods.

\section{Related Work}

% Here, talk about the related work you encountered for your approach. Cite at least 5 references. Refer to item 2. No one has done exactly your task? Write about the most similar thing you can find. This should be around 0.25-0.5 pages.

Many related works similarly tackle the task of crime prediction, albeit not necessarily with our identical approach or goal. 

Ibrahim et al. (2024) combined convolutional neural networks with k‑means clustering to predict crime rates, outperforming traditional models [1]. Ladha and Patyal (2024) compared k‑nearest neighbours, SVM, and decision trees to classify regions into high, medium, or low crime [2]. Walczak (2021) used neural models with geospatial and temporal inputs to predict both crime type and location, aligning most closely with our task [3]. Obagbuwa and Abidoye (2021) applied linear regression to forecast urban crime incidents in South African cities [4]. Kshatri et al. (2021) applied a stacking‑ensemble SVM in India and achieved very high accuracy, showing that combining models can improve predictions [5].

Overall, many studies have advanced crime forecasting, most commonly through deep learning. None adopt a unit of analysis as proposed in this project, allowing our approach to attempt a new gap.

\section{Dataset}
% You should write about your dataset here, following the guidelines regarding item 1. This section may be 0.5-1 pages. Depending on your specific dataset, you may want to include subsections for the preprocessing, annotation, etc.

The raw dataset consisted of over 1 million individual crime reports, transcribed from the original paper records. Each report included a date, time of occurrence, location, crime code, victim age, and other logistical attributes. The original dataset \href{https://www.kaggle.com/datasets/cityofLA/crime-in-los-angeles}{may be found here}.

To create a dataset suitable for the intended model, however, several restructuring steps were necessary.

\subsection{Preprocessing}
\begin{enumerate}
    \item Normalizing all column names in the provided \texttt{.csv} file, including aligning capitalization and trimming spaces.
    \item Dropping rows missing a time, date, or location, since these were essential identifiers.
    \item Dropping rows with coordinates outside the latitude and longitude bounds around Los Angeles (LA) (including a buffer margin).
    \item Grouping similar crimes that differ only by description technicalities.
\end{enumerate}

\subsection{Transformations}
\begin{enumerate}
    \item Spatial aggregation: The LA area (including a buffer margin) was divided into 2 km$^2$ grid cells, with each cell treated as a single ``spatial unit.''
    \item Temporal aggregation: Crimes were grouped by week number and year. For example, crimes occurring on Tuesday and Wednesday of the 3rd week of a year would belong to the same ``temporal unit.''
    \item Count aggregation: The combined spatial-temporal unit (grid cell $\times$ week) was used to count the number of crimes per type.
\end{enumerate}

After preprocessing and transformation, the final dataset consisted of grid cell-week units, each with counts for every crime type.

\section{Features}
% Describe any features you used for your model, or how your data was input to your model. Are you doing feature engineering or feature selection? Are you learning embeddings? Is it all part of one neural network? Refer to item 2. This may range from 0.25 pages to 0.5 pages.

The input features for the model include the aforementioned spatial and temporal identifiers, as well as engineered inputs derived from the dataset:

\begin{itemize}
    \item Rolling averages: Per crime type, the rolling average over the previous two weeks within the same grid cell was calculated. This transformed the raw counts into a new feature that captures short-term temporal trends.
    \item Neighbouring activity (planned): Aggregated counts from adjacent grid cells are planned to be incorporated in the future to capture local spatial correlations.
    \item Extended rolling averages (planned): Rolling averages from four to six weeks are planned to be incorporated to capture longer-term patterns in crime.
    \item Temporal effects (planned): Features encoding week-level seasonality, holidays, or day-of-week patterns may be included in the future, to better capture any temporal trends.
    \item Crime interactions (planned): Features capturing correlations between different crime types (e.g., theft vs. property damage) may be included in the future.
\end{itemize}

Each input is represented as a single feature vector per unit, with multiple outputs corresponding to the counts of each crime type, allowing the model to predict multiple targets simultaneously.

\section{Implementation}

The model was implemented as a multi-label logistic regression classifier using only NumPy and pandas. Each crime type is modeled as a separate binary logistic regression problem with its own weight vector and bias term. During training, the model learns to minimize the binary cross-entropy loss between the predicted probabilities and the true labels. The optimization is carried out using batch gradient descent with a fixed learning rate and a specified number of iterations.

The logistic regression was trained on rolling temporal features extracted from the training data, and predictions were generated for each week in the testing set. The output probabilities were converted into binary predictions using a 0.5 threshold. Accuracy was computed individually for each crime label by comparing predicted outcomes with actual occurrences. The model’s results and learned parameters were stored for further analysis and visualization.

This implementation offers a balance between how interpretable it is and predictive power. By avoiding reliance on high-level machine learning libraries, it provides clear insight into the mathematical foundations of logistic regression and allows the team to directly control every aspect of the training and evaluation process.

\section{Results and Evaluation}

The model’s performance was evaluated using standard multilabel classification metrics, including precision, recall, F1-score, and accuracy. Each crime type was treated as a separate binary classification task, and the metrics were computed individually before averaging across all labels to obtain macro-level performance. This approach ensures that each crime type contributes equally to the evaluation, regardless of how frequently it occurs.

During evaluation, the model’s predictions were compared against ground-truth labels in the testing set. The evaluation script generated a summary table showing per-label and overall scores, allowing for detailed comparison across different crime types. Crimes with more consistent patterns, such as theft and burglary, tended to show higher recall, while low-frequency crimes displayed slightly higher precision but lower recall. The F1-score provided a balanced view of performance across these trade-offs.

As a baseline, a simple frequency-based predictor was implemented to estimate crime occurrences based on the previous week’s averages. The logistic regression model outperformed this baseline in all major metrics, demonstrating its ability to generalize beyond recent history and identify broader temporal trends. Evaluation results were exported to \texttt{evaluation\_results.csv} for visualization and further analysis. Overall, these results establish a strong baseline and validate the effectiveness of the model’s rolling temporal features.

\section{Feedback and Plans}

Based on the feedback received, the next stage of this project will focus on expanding the modeling approach and improving both performance and interpretability. The team plans to experiment with different machine learning models, such as Random Forests and neural networks, to compare their predictive capabilities against the current logistic regression baseline. Regularization techniques, including L1 and L2 penalties, will be explored to improve generalization and reduce overfitting. 

Additionally, the feature preprocessing pipeline will be revisited to test alternative grouping strategies, such as aggregating related crime categories into broader classes to capture higher-level behavioral patterns. The team also aims to develop a spatial visualization component, creating an interactive map to display predicted crime hotspots across Los Angeles. This will improve interpretability and provide an intuitive way to analyze temporal and spatial crime trends. In general, these next steps will strengthen the performance of the model and present the results in a more informative and practical manner.

\section{References}
% Many websites where you can find academic papers also allow you to export a bib file for citation or bib formatted entry. Copy this into the \texttt{custom.bib} and you will be able to cite the paper in the \LaTeX{}. You can remove the example entries.

\renewcommand{\refname}{}
\vspace{-3em}

\begin{thebibliography}{9}

\bibitem{Ibrahim2024}
Abdulladeef Abubakar Ibrahim, Yusuf Musa Malgwi, Yahaya Ali.
\newblock A Hybrid Machine Learning Model for Crime Rate Prediction.
\newblock \emph{FUDMA Journal of Sciences}, 8(6):101--106, 2024.
\newblock \url{https://fjs.fudutsinma.edu.ng/index.php/fjs/article/view/2789}.

\bibitem{LadhaPatyal2023}
Priyanshu Ladha, Nitya Patyal.
\newblock Crime Rate Prediction Using Machine Learning.
\newblock In \emph{Advancements in Communication and Systems}, pages 359--368, 2023.
\newblock \url{https://www.academia.edu/129180374/Crime_Rate_Prediction_using_Machine_Learning}.

\bibitem{Walczak2021}
Bartłomiej Walczak.
\newblock Predicting crime and other uses of neural networks in police decision making.
\newblock \emph{Frontiers in Psychology}, 12:587943, 2021.
\newblock \url{https://www.frontiersin.org/journals/psychology/articles/10.3389/fpsyg.2021.587943/full}.

\bibitem{ObagbuwaAbidoye2021}
Ibidun Christiana Obagbuwa, Ademola P. Abidoye.
\newblock South Africa Crime Visualization, Trends Analysis and Prediction Using Machine Learning Linear Regression Technique.
\newblock \emph{Applied Computational Intelligence and Soft Computing}, 2021.
\newblock \url{https://doi.org/10.1155/2021/5537902}.

\bibitem{Kshatri2022}
Sapna Singh Kshatri et al.
\newblock An Empirical Analysis of Machine Learning Algorithms for Crime Prediction Using Stacked Generalisation – An Ensemble Approach.
\newblock In \emph{IEEE Access / IEEE International Conference}, 2022.
\newblock \url{https://ieeexplore.ieee.org/document/9410543}.

\end{thebibliography}

\section*{Team Contributions}

% Write in this section a few sentences describing the contributions of each team member. What did each member work on? Refer to item 7.

\textbf{Alina:} Defined what the training dataset would look like; programmed the sections for data preprocessing and feature engineering; wrote the report sections for dataset, features, and related work with references.

\textbf{Arjun:} Wrote the following sections of the report: introduction, model implementation, and feedback from the teaching assistant. Went to tutorial to gain feedback, programmed the main model section in the model.py file. 

% ====================================================================================================

% \section{Template Notes}

% You can remove this section or comment it out, as it only contains instructions for how to use this template. You may use subsections in your document as you find appropriate.

% \subsection{Tables and figures}

% See Table~\ref{citation-guide} for an example of a table and its caption.
% See Figure~\ref{fig:experiments} for an example of a figure and its caption.


% \begin{figure}[t]
%   \includegraphics[width=\columnwidth]{example-image-golden}
%   \caption{A figure with a caption that runs for more than one line.
%     Example image is usually available through the \texttt{mwe} package
%     without even mentioning it in the preamble.}
%   \label{fig:experiments}
% \end{figure}

% \begin{figure*}[t]
%   \includegraphics[width=0.48\linewidth]{example-image-a} \hfill
%   \includegraphics[width=0.48\linewidth]{example-image-b}
%   \caption {A minimal working example to demonstrate how to place
%     two images side-by-side.}
% \end{figure*}


% \subsection{Citations}

% \begin{table*}
%   \centering
%   \begin{tabular}{lll}
%     \hline
%     \textbf{Output}           & \textbf{natbib command} & \textbf{ACL only command} \\
%     \hline
%     \citep{Gusfield:97}       & \verb|\citep|           &                           \\
%     \citealp{Gusfield:97}     & \verb|\citealp|         &                           \\
%     \citet{Gusfield:97}       & \verb|\citet|           &                           \\
%     \citeyearpar{Gusfield:97} & \verb|\citeyearpar|     &                           \\
%     \citeposs{Gusfield:97}    &                         & \verb|\citeposs|          \\
%     \hline
%   \end{tabular}
%   \caption{\label{citation-guide}
%     Citation commands supported by the style file.
%   }
% \end{table*}

% Table~\ref{citation-guide} shows the syntax supported by the style files.
% We encourage you to use the natbib styles.
% You can use the command \verb|\citet| (cite in text) to get ``author (year)'' citations, like this citation to a paper by \citet{Gusfield:97}.
% You can use the command \verb|\citep| (cite in parentheses) to get ``(author, year)'' citations \citep{Gusfield:97}.
% You can use the command \verb|\citealp| (alternative cite without parentheses) to get ``author, year'' citations, which is useful for using citations within parentheses (e.g. \citealp{Gusfield:97}).

% \subsection{References}

% \nocite{Ando2005,andrew2007scalable,rasooli-tetrault-2015}

% Many websites where you can find academic papers also allow you to export a bib file for citation or bib formatted entry. Copy this into the \texttt{custom.bib} and you will be able to cite the paper in the \LaTeX{}. You can remove the example entries.

% \subsection{Equations}

% An example equation is shown below:
% \begin{equation}
%   \label{eq:example}
%   A = \pi r^2
% \end{equation}

% Labels for equation numbers, sections, subsections, figures and tables
% are all defined with the \verb|\label{label}| command and cross references
% to them are made with the \verb|\ref{label}| command.
% This an example cross-reference to Equation~\ref{eq:example}. You can also write equations inline, like this: $A=\pi r^2$.


% % \section*{Limitations}

% % Bibliography entries for the entire Anthology, followed by custom entries
% %\bibliography{custom,anthology-overleaf-1,anthology-overleaf-2}

% % Custom bibliography entries only
% \bibliography{custom}

% % \appendix

% % \section{Example Appendix}
% % \label{sec:appendix}

% % This is an appendix.

\end{document}
